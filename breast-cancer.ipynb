{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Gerekli Kütüphaneler"
      ],
      "metadata": {
        "id": "9i7sfIQgeiZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Colab'da varsayılan olarak yüklü gelmeyenleri kuruyoruz\n",
        "!pip install optuna\n",
        "!pip install shap\n",
        "\n",
        "# Temel Veri İşleme ve Görselleştirme\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Scikit-learn: Veri Yükleme ve Ön İşleme\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Scikit-learn: Model ve Metrikler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score,\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    auc\n",
        ")\n",
        "\n",
        "# İleri Seviye: Optimizasyon ve Açıklanabilirlik (XAI)\n",
        "import optuna\n",
        "import shap\n",
        "\n",
        "# Pandas ayarları (Tüm sütunları görmek için)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "print(\"Tüm kütüphaneler başarıyla yüklendi ve hazır!\")"
      ],
      "metadata": {
        "id": "8O65SMIgeikQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Veri Setinin Yüklenmesi**"
      ],
      "metadata": {
        "id": "tG7MiypmT0HZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.1 scikit-learn'den Veri Seti Yükleme"
      ],
      "metadata": {
        "id": "6tMtTEPiXKAz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWB5AxVvTXmc"
      },
      "outputs": [],
      "source": [
        "# Veri setini yükle\n",
        "data = load_breast_cancer()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.2 Veri Çerçevesi Oluşturma"
      ],
      "metadata": {
        "id": "BsiH1qZKW56U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X (özellikler) ve y (hedef) değişkenlerini ayırma\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# pandas DataFrame formatına dönüştürme\n",
        "df = pd.DataFrame(X, columns=data.feature_names)\n",
        "df['target'] = y\n",
        "\n",
        "# İlk 5 satırı görüntüleme\n",
        "print(\"Veri Setinin İlk 5 Satırı\")\n",
        "display(df.head())"
      ],
      "metadata": {
        "id": "oN8CqD4fW6FD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Veri Seti Kalite Kontrolleri**"
      ],
      "metadata": {
        "id": "XYuAu63tXz7G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.1 Eksik Değer Analizi"
      ],
      "metadata": {
        "id": "K6ltXhUpX8uw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nEksik Değer Kontrolü\")\n",
        "missing_values = df.isnull().sum()\n",
        "\n",
        "# Eksik değer varsa uygun yöntemle dolduruyoruz\n",
        "if missing_values.sum() == 0:\n",
        "    print(\"Sonuç: Veri setinde eksik değer bulunmamaktadır.\")\n",
        "else:\n",
        "    df.fillna(df.mean(), inplace=True)\n",
        "    print(\"Sonuç: Eksik değerler ortalama ile dolduruldu.\")"
      ],
      "metadata": {
        "id": "4Zf-bc6gX0J6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.2 Aykırı Değer (Outlier) Analizi - IQR Yöntemi"
      ],
      "metadata": {
        "id": "DvUHzFBkYUlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nAykırı Değer Analizi (IQR Yöntemi)\")\n",
        "def detect_outliers_iqr(dataframe, columns):\n",
        "    outlier_indices = []\n",
        "    for col in columns:\n",
        "        # Çeyreklikler (Q1 ve Q3) hesaplanıyor\n",
        "        Q1 = dataframe[col].quantile(0.25)\n",
        "        Q3 = dataframe[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "\n",
        "        # Alt ve üst sınırlar belirleniyor\n",
        "        outlier_step = 1.5 * IQR\n",
        "\n",
        "        # Sınırlara uymayan değerler tespit ediliyor\n",
        "        outliers_col = dataframe[(dataframe[col] < Q1 - outlier_step) | (dataframe[col] > Q3 + outlier_step)].index\n",
        "        if len(outliers_col) > 0:\n",
        "            outlier_indices.extend(outliers_col)\n",
        "\n",
        "    return list(set(outlier_indices))\n",
        "\n",
        "# Sadece özellik sütunlarında outlier aranıyor\n",
        "outliers = detect_outliers_iqr(df, data.feature_names)\n",
        "print(f\"IQR yöntemiyle tespit edilen aykırı değer içeren satır sayısı: {len(outliers)}\")"
      ],
      "metadata": {
        "id": "8ToSHGk4YU08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.3 Veri Tipi ve Dağılım İncelemesi"
      ],
      "metadata": {
        "id": "FAD8qO2jYp8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nVeri Tipleri\")\n",
        "# Sütunların dtype bilgilerini göster\n",
        "print(df.dtypes)\n",
        "\n",
        "print(\"\\nHedef Değişken Dağılımı (Sayısal/Kategorik)\")\n",
        "# Sayısal / kategorik değişken sayılarını raporla\n",
        "print(df['target'].value_counts())"
      ],
      "metadata": {
        "id": "rQ_JOGhEYqGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Keşifsel Veri Analizi (EDA)**"
      ],
      "metadata": {
        "id": "kV-W8Y4GZ6Lp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.1 İstatistiksel Özellikler"
      ],
      "metadata": {
        "id": "01_CiRaTaCvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean, Median, Min-Max, Std, Q1-Q3 değerleri hesaplanıyor\n",
        "print(\"\\nİstatistiksel Özellikler Tablosu\")\n",
        "istatistikler = df.describe().T\n",
        "display(istatistikler[['mean', '50%', 'min', 'max', 'std', '25%', '75%']])"
      ],
      "metadata": {
        "id": "aUg_bT2tZ6a-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.2 Korelasyon Matrisi ve Heatmap"
      ],
      "metadata": {
        "id": "NYicV24caSiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pearson korelasyon matrisi oluşturuluyor\n",
        "plt.figure(figsize=(18, 14))\n",
        "corr_matrix = df.corr()\n",
        "\n",
        "# Heatmap ile görselleştiriliyor\n",
        "sns.heatmap(corr_matrix, annot=True, fmt=\".1f\", cmap='coolwarm', linewidths=0.5)\n",
        "plt.title(\"Pearson Korelasyon Matrisi\")\n",
        "plt.show()\n",
        "\n",
        "# En yüksek korelasyonlu 3 çift sütunu yorumluyoruz\n",
        "print(\"\\nEn Yüksek Korelasyonlu 3 Çift\")\n",
        "corr_unstack = corr_matrix.abs().unstack()\n",
        "corr_unstack = corr_unstack[corr_unstack < 1] # Kendisiyle (1.0) olanları çıkarıyoruz\n",
        "print(corr_unstack.sort_values(ascending=False).drop_duplicates().head(3))"
      ],
      "metadata": {
        "id": "721p_2iSaSrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.3 Boxplot Analizi"
      ],
      "metadata": {
        "id": "F_6QNoEdcsnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tüm özellikler için boxplot çiziliyor\n",
        "plt.figure(figsize=(20, 8))\n",
        "data_melted = pd.melt(df.drop('target', axis=1), var_name=\"Features\", value_name=\"Value\")\n",
        "sns.boxplot(x=\"Features\", y=\"Value\", data=data_melted)\n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Özellikler için Boxplot Analizi (Aykırı Değerler)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZibLJA2Ecsy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Veri Ölçeklendirme (Scaling)**"
      ],
      "metadata": {
        "id": "jf4CXWaVdKww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "# Ölçeklendirilmiş veriyi X_scaled olarak kaydediyoruz\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(\"\\nÖlçeklendirme Tamamlandı\")\n",
        "print(f\"X_scaled boyutu: {X_scaled.shape}\")\n",
        "print(f\"Örnek (İlk sütun ortalaması ~0 olmalı): {X_scaled[:,0].mean():.2f}\")"
      ],
      "metadata": {
        "id": "nbzRR1ABdLAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Veri Setinin Bölünmesi**"
      ],
      "metadata": {
        "id": "Wu9rb7lsoeOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Yönerge: %70 Training, %10 Validation, %20 Test\n",
        "\n",
        "# Adım 1: Önce Test setini (%20) ayırıyoruz.\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.20, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Adım 2: Kalan veriyi (%80) Train ve Validation olarak bölüyoruz.\n",
        "# Toplamın %10'u validasyon olacaksa, kalan %80'in 1/8'i validasyondur.\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.125, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "print(f\"Training Set (%70): {X_train.shape}\")\n",
        "print(f\"Validation Set (%10): {X_val.shape}\")\n",
        "print(f\"Test Set (%20): {X_test.shape}\")"
      ],
      "metadata": {
        "id": "MjsJI3WtoeYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Farklı MLP Modellerinin Kurulması**"
      ],
      "metadata": {
        "id": "YrDCsoL0pdYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Yönergede belirtilen 5 farklı model konfigürasyonu tanımlanıyor\n",
        "models_config = [\n",
        "    {\n",
        "        \"name\": \"Model 1 - Basit\",\n",
        "        \"params\": {\"hidden_layer_sizes\": (16,), \"activation\": \"relu\", \"learning_rate_init\": 0.001}\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Model 2 - Orta\",\n",
        "        \"params\": {\"hidden_layer_sizes\": (32, 16), \"activation\": \"relu\", \"learning_rate_init\": 0.005}\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Model 3 - Geniş\",\n",
        "        \"params\": {\"hidden_layer_sizes\": (64, 64), \"activation\": \"tanh\", \"learning_rate_init\": 0.001}\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Model 4 - Derin\",\n",
        "        \"params\": {\"hidden_layer_sizes\": (128, 64, 32), \"activation\": \"relu\", \"learning_rate_init\": 0.0005}\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Model 5 - Düşük LR\",\n",
        "        \"params\": {\"hidden_layer_sizes\": (32,), \"activation\": \"relu\", \"learning_rate_init\": 0.0001}\n",
        "    }\n",
        "]\n",
        "\n",
        "results = []\n",
        "trained_models = {} # Modelleri daha sonra kullanmak için saklıyoruz\n",
        "\n",
        "print(\"\\nModeller Eğitiliyor\")"
      ],
      "metadata": {
        "id": "N4f_OJN2pdiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Validation Performanslarının Ölçülmesi**"
      ],
      "metadata": {
        "id": "lHyoENBPpub3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for config in models_config:\n",
        "    # Model oluşturuluyor ve eğitiliyor\n",
        "    mlp = MLPClassifier(**config[\"params\"], max_iter=1000, random_state=42, early_stopping=True)\n",
        "    mlp.fit(X_train, y_train)\n",
        "\n",
        "    # Validation seti üzerinde tahminler yapılıyor\n",
        "    y_pred = mlp.predict(X_val)\n",
        "    y_proba = mlp.predict_proba(X_val)[:, 1] # ROC-AUC için olasılık değerleri\n",
        "\n",
        "    # İstenen metrikler hesaplanıyor\n",
        "    acc = accuracy_score(y_val, y_pred)\n",
        "    prec = precision_score(y_val, y_pred)\n",
        "    rec = recall_score(y_val, y_pred)\n",
        "    f1 = f1_score(y_val, y_pred)\n",
        "    roc = roc_auc_score(y_val, y_proba)\n",
        "\n",
        "    # Sonuçları listeye ekliyoruz\n",
        "    results.append({\n",
        "        \"Model\": config[\"name\"],\n",
        "        \"Accuracy\": acc,\n",
        "        \"Precision\": prec,\n",
        "        \"Recall\": rec,\n",
        "        \"F1-Score\": f1,\n",
        "        \"ROC-AUC\": roc\n",
        "    })\n",
        "\n",
        "    # Modeli kaydediyoruz\n",
        "    trained_models[config[\"name\"]] = mlp\n",
        "\n",
        "# Tüm modellerin performanslarını tablo halinde gösteriyoruz\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\nValidation Seti Performans Karşılaştırması\")\n",
        "display(results_df)"
      ],
      "metadata": {
        "id": "S1O2jDbUpusZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8. En İyi Modelin Test Üzerinde Değerlendirilmesi**"
      ],
      "metadata": {
        "id": "plKaahN9p57p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation sonuçlarına göre (F1-Score baz alınarak) en iyi modeli seçiyoruz\n",
        "best_model_name = results_df.sort_values(by=\"F1-Score\", ascending=False).iloc[0][\"Model\"]\n",
        "best_model = trained_models[best_model_name]\n",
        "print(f\"\\nSeçilen En İyi Model: {best_model_name}\")"
      ],
      "metadata": {
        "id": "LxAah9mOp6GT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.1 Performans Metrikleri"
      ],
      "metadata": {
        "id": "JH65O9C0qPXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = best_model.predict(X_test)\n",
        "y_test_proba = best_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"\\nTest Seti Performansı\")\n",
        "print(f\"Accuracy:  {accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_test_pred):.4f}\")\n",
        "print(f\"Recall:    {recall_score(y_test, y_test_pred):.4f}\")\n",
        "print(f\"F1-Score:  {f1_score(y_test, y_test_pred):.4f}\")\n",
        "print(f\"ROC-AUC:   {roc_auc_score(y_test, y_test_proba):.4f}\")"
      ],
      "metadata": {
        "id": "_MjqgmFJqPiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.2 Confusion Matrix"
      ],
      "metadata": {
        "id": "1GfhIdS5qXNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_test_pred)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title(f\"Confusion Matrix ({best_model_name})\")\n",
        "plt.ylabel('Gerçek Değerler')\n",
        "plt.xlabel('Tahmin Edilen Değerler')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p49SqB0NqXYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.3 ROC Eğrisi"
      ],
      "metadata": {
        "id": "0xoeaPIfqdC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_test, y_test_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Eğrisi')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m_rx0PMLqdOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **9. Optuna ile Hiperparametre Optimizasyonu (150 Deneme)**"
      ],
      "metadata": {
        "id": "BAfDL8OfquHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adım 1: Optuna Objective Fonksiyonu Tanımlama\n",
        "def objective(trial):\n",
        "\n",
        "    # 9.2 Arama Aralıkları\n",
        "\n",
        "    # Katman sayısı (1 ile 3 arasında)\n",
        "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
        "    layers = []\n",
        "    for i in range(n_layers):\n",
        "        # Her katmandaki nöron sayısı\n",
        "        layers.append(trial.suggest_int(f\"n_units_l{i}\", 16, 256))\n",
        "\n",
        "    # Diğer hiperparametreler\n",
        "    learning_rate_init = trial.suggest_float(\"learning_rate_init\", 1e-5, 1e-1, log=True)\n",
        "    alpha = trial.suggest_float(\"alpha\", 1e-6, 1e-2, log=True)\n",
        "    activation = trial.suggest_categorical(\"activation\", [\"relu\", \"tanh\"])\n",
        "    solver = trial.suggest_categorical(\"solver\", [\"adam\", \"sgd\"])\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64, 128])\n",
        "\n",
        "    # Modeli Kurma\n",
        "    clf = MLPClassifier(\n",
        "        hidden_layer_sizes=tuple(layers),\n",
        "        learning_rate_init=learning_rate_init,\n",
        "        alpha=alpha,\n",
        "        activation=activation,\n",
        "        solver=solver,\n",
        "        batch_size=batch_size,\n",
        "        max_iter=200, # Hızlandırmak için 200, sınır yoksa 500-1000 olabilir\n",
        "        random_state=42,\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "    # 9.3 Eğitim Döngüsü\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Validation Skoru\n",
        "    val_acc = accuracy_score(y_val, clf.predict(X_val))\n",
        "\n",
        "    return val_acc\n",
        "\n",
        "# Adım 2: Optimizasyonu Başlatma\n",
        "print(\"Optuna Optimizasyonu Başlatılıyor (150 Deneme)\")\n",
        "# 'study' değişkeni\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=150)\n",
        "\n",
        "# Adım 3: Sonuçları Raporlama (9.4)\n",
        "print(\"\\nOptuna Tarafından Bulunan En İyi Parametreler\")\n",
        "print(study.best_params)\n",
        "print(f\"En İyi Validation Accuracy Değeri: {study.best_value:.4f}\")\n",
        "\n",
        "# Adım 4: En İyi Modeli Yeniden Eğitme (SHAP için hazırlık)\n",
        "print(\"\\nEn iyi model yeniden eğitiliyor...\")\n",
        "best_params = study.best_params.copy()\n",
        "\n",
        "# Parametreleri modele uygun hale getirme\n",
        "layers = []\n",
        "for k, v in best_params.items():\n",
        "    if k.startswith(\"n_units\"):\n",
        "        layers.append(v)\n",
        "\n",
        "final_params = {k: v for k, v in best_params.items() if not k.startswith(\"n_units\") and k != \"n_layers\"}\n",
        "\n",
        "optuna_model = MLPClassifier(hidden_layer_sizes=tuple(layers), **final_params, max_iter=1000, random_state=42)\n",
        "optuna_model.fit(X_train, y_train)\n",
        "print(\"Optuna modeli başarıyla oluşturuldu ve eğitildi.\")"
      ],
      "metadata": {
        "id": "74yk2NxhrRVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **10. XAI - SHAP Açıklanabilirlik Analizi**"
      ],
      "metadata": {
        "id": "9nYCUkWRsNRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Yardımcı fonksiyon:\n",
        "# SHAP çıktısını (eski / yeni) formata göre sınıf 1 için 2D matrise çevir\n",
        "def get_class_shap_matrix(shap_values, class_idx=1):\n",
        "    \"\"\"\n",
        "    SHAP farklı versiyonlarda farklı şekiller döndürebiliyor:\n",
        "    - Eski stil: list of arrays: [array(nsamples, nfeatures), array(nsamples, nfeatures)]\n",
        "    - Yeni stil: array(nsamples, nfeatures, nclasses)\n",
        "    Bu fonksiyon hepsini nsamples x nfeatures forma çevirip geri döner.\n",
        "    \"\"\"\n",
        "    # 1) List of arrays ise (eski API)\n",
        "    if isinstance(shap_values, list):\n",
        "        return shap_values[class_idx]\n",
        "\n",
        "    # 2) array'e çevir\n",
        "    sv = np.array(shap_values)\n",
        "\n",
        "    # Tek çıkışlı model (nsamples, nfeatures)\n",
        "    if sv.ndim == 2:\n",
        "        return sv\n",
        "\n",
        "    # Çok çıkışlı model (muhtemelen nsamples, nfeatures, nclasses)\n",
        "    if sv.ndim == 3:\n",
        "        # nsamples x nfeatures x nclasses - sınıf 1'in 2D matrisi\n",
        "        return sv[:, :, class_idx]\n",
        "\n",
        "    raise ValueError(f\"Beklenmeyen shap_values boyutu: {sv.shape}\")\n",
        "\n",
        "# 0) X_train / X_test'i numpy'a çevir\n",
        "if hasattr(X_train, \"values\"):\n",
        "    X_train_np = X_train.values\n",
        "else:\n",
        "    X_train_np = X_train\n",
        "\n",
        "if hasattr(X_test, \"values\"):\n",
        "    X_test_np = X_test.values\n",
        "else:\n",
        "    X_test_np = X_test\n",
        "\n",
        "feature_names = list(data.feature_names)\n",
        "\n",
        "print(\"X_train_np shape:\", X_train_np.shape)\n",
        "print(\"X_test_np shape:\", X_test_np.shape)\n",
        "print(\"Özellik sayısı:\", len(feature_names))\n",
        "\n",
        "assert X_train_np.shape[1] == len(feature_names), \"X_train ile feature_names kolon sayısı uyuşmuyor!\"\n",
        "assert X_test_np.shape[1] == len(feature_names), \"X_test ile feature_names kolon sayısı uyuşmuyor!\"\n",
        "\n",
        "# SHAP grafikleri için JS başlat\n",
        "shap.initjs()\n",
        "\n",
        "# 1) Background (özet) veri: KernelExplainer için k-means\n",
        "X_train_summary = shap.kmeans(X_train_np, 10)\n",
        "print(\"SHAP için background veri hazırlandı.\")\n",
        "\n",
        "# 10.1 Seçilen MLP Modeli (best_model) İçin SHAP Analizi\n",
        "print(f\"\\n10.1 SHAP Analizi: {best_model_name} (Elle Seçilen En İyi Model)\")\n",
        "\n",
        "X_test_sample = X_test_np\n",
        "\n",
        "# Explainer oluşturuluyor\n",
        "explainer = shap.KernelExplainer(best_model.predict_proba, X_train_summary)\n",
        "\n",
        "# SHAP değerleri hesaplanıyor\n",
        "raw_shap_values = explainer.shap_values(X_test_sample)\n",
        "\n",
        "print(\"raw_shap_values type:\", type(raw_shap_values))\n",
        "print(\"np.array(raw_shap_values).shape:\", np.array(raw_shap_values).shape)\n",
        "\n",
        "# Sınıf 1 için (pozitif sınıf) nsamples x nfeatures SHAP matrisi\n",
        "shap_values_class1 = get_class_shap_matrix(raw_shap_values, class_idx=1)\n",
        "\n",
        "print(\"shap_values_class1 shape:\", shap_values_class1.shape)\n",
        "\n",
        "assert shap_values_class1.shape[0] == X_test_sample.shape[0], \"Satır sayısı (örnek sayısı) uyuşmuyor!\"\n",
        "assert shap_values_class1.shape[1] == X_test_sample.shape[1], \"Kolon sayısı (özellik sayısı) uyuşmuyor!\"\n",
        "\n",
        "# Grafik 1: Özelliklerin Önem Sıralaması (Bar Plot)\n",
        "print(\"Grafik 1: Özelliklerin Önem Sıralaması (Bar Plot)\")\n",
        "plt.figure()\n",
        "shap.summary_plot(\n",
        "    shap_values_class1,\n",
        "    X_test_sample,\n",
        "    feature_names=feature_names,\n",
        "    plot_type=\"bar\"\n",
        ")\n",
        "\n",
        "# Grafik 2: Özellik Değerlerinin Etkisi (Summary Dot Plot)\n",
        "print(\"Grafik 2: Özellik Değerlerinin Etkisi (Summary Plot)\")\n",
        "plt.figure()\n",
        "shap.summary_plot(\n",
        "    shap_values_class1,\n",
        "    X_test_sample,\n",
        "    feature_names=feature_names\n",
        ")\n",
        "\n",
        "# 10.2 Optuna ile Bulunan En İyi Model (optuna_model) SHAP\n",
        "print(\"\\nSHAP Analizi: Optuna Tarafından Bulunan Model\")\n",
        "\n",
        "# Aynı background veriyi kullanıyoruz\n",
        "explainer_opt = shap.KernelExplainer(optuna_model.predict_proba, X_train_summary)\n",
        "\n",
        "X_test_sample_opt = X_test_np\n",
        "\n",
        "raw_shap_values_opt = explainer_opt.shap_values(X_test_sample_opt)\n",
        "\n",
        "print(\"np.array(raw_shap_values_opt).shape:\", np.array(raw_shap_values_opt).shape)\n",
        "\n",
        "shap_values_opt_class1 = get_class_shap_matrix(raw_shap_values_opt, class_idx=1)\n",
        "\n",
        "print(\"shap_values_opt_class1 shape:\", shap_values_opt_class1.shape)\n",
        "\n",
        "assert shap_values_opt_class1.shape[0] == X_test_sample_opt.shape[0], \"Satır sayısı uyuşmuyor! (optuna_model)\"\n",
        "assert shap_values_opt_class1.shape[1] == X_test_sample_opt.shape[1], \"Kolon sayısı uyuşmuyor! (optuna_model)\"\n",
        "\n",
        "# Grafik 3: Optuna Modeli Genel Bakış (Summary Plot)\n",
        "print(\"Grafik 3: Optuna Modeli Genel Bakış (Summary Plot)\")\n",
        "plt.figure()\n",
        "shap.summary_plot(\n",
        "    shap_values_opt_class1,\n",
        "    X_test_sample_opt,\n",
        "    feature_names=feature_names\n",
        ")\n",
        "\n",
        "# Grafik 4: Force Plot (Tek bir örnek için karar açıklaması)\n",
        "print(\"Grafik 4: Tek Bir Örnek İçin Karar Açıklaması (Force Plot)\")\n",
        "\n",
        "force_fig = shap.force_plot(\n",
        "    explainer_opt.expected_value[1] if np.ndim(explainer_opt.expected_value) > 0 else explainer_opt.expected_value,\n",
        "    shap_values_opt_class1[0, :],\n",
        "    X_test_sample_opt[0, :],\n",
        "    feature_names=feature_names,\n",
        "    matplotlib=True\n",
        ")\n",
        "plt.show()\n",
        "\n",
        "# Grafik 5: Decision Plot (Karar yolu - ilk 10 örnek)\n",
        "print(\"Grafik 5: Karar Yolu (Decision Plot - İlk 10 Örnek)\")\n",
        "shap.decision_plot(\n",
        "    explainer_opt.expected_value[1] if np.ndim(explainer_opt.expected_value) > 0 else explainer_opt.expected_value,\n",
        "    shap_values_opt_class1[:10],\n",
        "    feature_names=feature_names\n",
        ")\n"
      ],
      "metadata": {
        "id": "z4AEpiwrsNc2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}